{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVRO - Data - Excersices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jar files \n",
    "# from pyspark.conf import SparkConf\n",
    "\n",
    "# conf = SparkConf()\n",
    "# conf.set(\"spark.jars.packages\", \"com.databricks:spark-avro_2.11:4.0.0\")\n",
    "\n",
    "# spark = SparkSession.builder.appName('AVRO-Excersices-NEW').master('yarn'). \\\n",
    "#                     config(conf= conf). \\\n",
    "#                     getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('AVRO-Excersices-NEW').master('yarn'). \\\n",
    "                    config(\"spark.jars.packages\", \"com.databricks:spark-avro_2.11:4.0.0\"). \\\n",
    "                    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gw01.itversity.com:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AVRO-Excersices-NEW</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7efef0f8d5f8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0.2.6.5.0-292'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.history.kerberos.keytab', 'none')\n",
      "('spark.eventLog.enabled', 'true')\n",
      "('spark.dynamicAllocation.initialExecutors', '2')\n",
      "('spark.history.ui.port', '18081')\n",
      "('spark.dynamicAllocation.maxExecutors', '10')\n",
      "('spark.driver.extraLibraryPath', '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64')\n",
      "('spark.yarn.dist.jars', 'file:///home/akashpatel/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar,file:///home/akashpatel/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.avro_avro-1.7.6.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar,file:///home/akashpatel/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar,file:///home/akashpatel/.ivy2/jars/org.tukaani_xz-1.0.jar')\n",
      "('spark.executor.extraLibraryPath', '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64')\n",
      "('spark.ui.proxyBase', '/proxy/application_1565300265360_73065')\n",
      "('spark.driver.host', 'gw01.itversity.com')\n",
      "('spark.history.provider', 'org.apache.spark.deploy.history.FsHistoryProvider')\n",
      "('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS', 'rm01.itversity.com')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.yarn.dist.pyFiles', 'file:///home/akashpatel/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar,file:///home/akashpatel/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.avro_avro-1.7.6.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar,file:///home/akashpatel/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar,file:///home/akashpatel/.ivy2/jars/org.tukaani_xz-1.0.jar')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.ui.filters', 'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter')\n",
      "('spark.driver.port', '42465')\n",
      "('spark.eventLog.dir', 'hdfs:///spark2-history/')\n",
      "('spark.dynamicAllocation.executorIdleTimeout', '120s')\n",
      "('spark.shuffle.service.enabled', 'true')\n",
      "('spark.app.name', 'AVRO-Excersices-NEW')\n",
      "('spark.executorEnv.PYTHONPATH', '/usr/hdp/current/spark2-client/python/lib/py4j-0.10.6-src.zip:/usr/hdp/current/spark2-client/python/<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.6-src.zip<CPS>{{PWD}}/com.databricks_spark-avro_2.11-4.0.0.jar<CPS>{{PWD}}/org.slf4j_slf4j-api-1.7.5.jar<CPS>{{PWD}}/org.apache.avro_avro-1.7.6.jar<CPS>{{PWD}}/org.codehaus.jackson_jackson-core-asl-1.9.13.jar<CPS>{{PWD}}/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar<CPS>{{PWD}}/com.thoughtworks.paranamer_paranamer-2.3.jar<CPS>{{PWD}}/org.xerial.snappy_snappy-java-1.0.5.jar<CPS>{{PWD}}/org.apache.commons_commons-compress-1.4.1.jar<CPS>{{PWD}}/org.tukaani_xz-1.0.jar')\n",
      "('spark.yarn.queue', 'default')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.jars.packages', 'com.databricks:spark-avro_2.11:4.0.0')\n",
      "('spark.yarn.secondary.jars', 'com.databricks_spark-avro_2.11-4.0.0.jar,org.slf4j_slf4j-api-1.7.5.jar,org.apache.avro_avro-1.7.6.jar,org.codehaus.jackson_jackson-core-asl-1.9.13.jar,org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,com.thoughtworks.paranamer_paranamer-2.3.jar,org.xerial.snappy_snappy-java-1.0.5.jar,org.apache.commons_commons-compress-1.4.1.jar,org.tukaani_xz-1.0.jar')\n",
      "('spark.history.fs.logDirectory', 'hdfs:///spark2-history/')\n",
      "('spark.master', 'yarn')\n",
      "('spark.repl.local.jars', 'file:///home/akashpatel/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar,file:///home/akashpatel/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.avro_avro-1.7.6.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/akashpatel/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar,file:///home/akashpatel/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar,file:///home/akashpatel/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar,file:///home/akashpatel/.ivy2/jars/org.tukaani_xz-1.0.jar')\n",
      "('spark.sql.catalogImplementation', 'hive')\n",
      "('spark.history.kerberos.principal', 'none')\n",
      "('spark.driver.appUIAddress', 'http://gw01.itversity.com:4041')\n",
      "('spark.submit.pyFiles', '/home/akashpatel/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar,/home/akashpatel/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar,/home/akashpatel/.ivy2/jars/org.apache.avro_avro-1.7.6.jar,/home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,/home/akashpatel/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,/home/akashpatel/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar,/home/akashpatel/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar,/home/akashpatel/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar,/home/akashpatel/.ivy2/jars/org.tukaani_xz-1.0.jar')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.dynamicAllocation.minExecutors', '0')\n",
      "('spark.yarn.isPython', 'true')\n",
      "('spark.app.id', 'application_1565300265360_73075')\n",
      "('spark.dynamicAllocation.enabled', 'true')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.yarn.historyServer.address', 'nn02.itversity.com:18081')\n",
      "('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES', 'http://rm01.itversity.com:19088/proxy/application_1565300265360_73075')\n",
      "('spark.sql.warehouse.dir', '/apps/hive/warehouse')\n"
     ]
    }
   ],
   "source": [
    "for i in spark.sparkContext.getConf().getAll():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "-rw-r--r--   2 akashpatel hdfs        256 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/README.txt\n",
      "-rw-r--r--   2 akashpatel hdfs       1471 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata.avsc\n",
      "-rw-r--r--   2 akashpatel hdfs      93561 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata1.avro\n",
      "-rw-r--r--   2 akashpatel hdfs      92214 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata2.avro\n",
      "-rw-r--r--   2 akashpatel hdfs      93421 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata3.avro\n",
      "-rw-r--r--   2 akashpatel hdfs      91340 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata4.avro\n",
      "-rw-r--r--   2 akashpatel hdfs      92214 2020-04-16 15:02 /user/akashpatel/dataset/sample-data/avro/userdata5.avro\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/dataset/sample-data/avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro = spark.read.format('com.databricks.spark.avro').load('/user/akashpatel/dataset/sample-data/avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|   registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03T07:55:29Z|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03T17:04:03Z|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|            null|   Canada|1/16/1968|150280.17|   Accountant IV|        |\n",
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_avro.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avro.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 items\n",
      "drwx------   - akashpatel hdfs          0 2020-04-17 15:24 /user/akashpatel/.Trash\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-17 15:06 /user/akashpatel/.sparkStaging\n",
      "drwx------   - akashpatel hdfs          0 2020-04-11 23:14 /user/akashpatel/.staging\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-02 10:50 /user/akashpatel/airlines_all\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-17 11:49 /user/akashpatel/avro_exercise\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-03-04 09:55 /user/akashpatel/cards\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-16 15:02 /user/akashpatel/dataset\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-17 15:22 /user/akashpatel/exercises\n",
      "-rw-r--r--   2 akashpatel hdfs      85492 2020-04-11 23:21 /user/akashpatel/json-serde-1.3.8-jar-with-dependencies.jar\n",
      "-rw-r--r--   2 akashpatel hdfs     139640 2020-04-11 22:54 /user/akashpatel/jsonserde.jar\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-11 10:22 /user/akashpatel/nyse_data\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-07 16:29 /user/akashpatel/project_demo\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-10 23:33 /user/akashpatel/retail_db\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-14 12:57 /user/akashpatel/top_10_businesses_per_city\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-03-29 22:30 /user/akashpatel/top_10_businesses_review_count\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-14 21:55 /user/akashpatel/top_3_useful_restaurant_reviews\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-03-29 23:22 /user/akashpatel/top_3_useful_restaurant_reviews_without_compression\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-03-16 11:07 /user/akashpatel/yelp\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -ls /user/akashpatel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `/user/akashpatel/exercises/avro_dataset/output': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /user/akashpatel/exercises/avro_dataset/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write.format(\"com.databricks.spark.avro\").save(\"/user/akashpatel/exercises/avro_dataset/output/avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 akashpatel hdfs          0 2020-04-17 15:29 /user/akashpatel/exercises/avro_dataset/output/avro/_SUCCESS\n",
      "-rw-r--r--   2 akashpatel hdfs     360409 2020-04-17 15:29 /user/akashpatel/exercises/avro_dataset/output/avro/part-00000-868529e6-b652-4093-a814-68fce9f1a66f-c000.avro\n",
      "-rw-r--r--   2 akashpatel hdfs      90834 2020-04-17 15:29 /user/akashpatel/exercises/avro_dataset/output/avro/part-00001-868529e6-b652-4093-a814-68fce9f1a66f-c000.avro\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/exercises/avro_dataset/output/avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.databricks.spark.avro\").load(\"/user/akashpatel/exercises/avro_dataset/output/avro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write.format(\"parquet\").save(\"/user/akashpatel/exercises/avro_dataset/output/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 akashpatel hdfs          0 2020-04-17 15:32 /user/akashpatel/exercises/avro_dataset/output/parquet/_SUCCESS\n",
      "-rw-r--r--   2 akashpatel hdfs     232634 2020-04-17 15:32 /user/akashpatel/exercises/avro_dataset/output/parquet/part-00000-d4cfa3a2-7a87-42c5-97ea-8c274dbb1caa-c000.snappy.parquet\n",
      "-rw-r--r--   2 akashpatel hdfs      72291 2020-04-17 15:32 /user/akashpatel/exercises/avro_dataset/output/parquet/part-00001-d4cfa3a2-7a87-42c5-97ea-8c274dbb1caa-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/exercises/avro_dataset/output/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.format(\"parquet\").load(\"/user/akashpatel/exercises/avro_dataset/output/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquet.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write.format(\"orc\").save(\"/user/akashpatel/excercises/avro_dataset/output/orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 akashpatel hdfs          0 2020-04-17 15:36 /user/akashpatel/excercises/avro_dataset/output/orc/_SUCCESS\n",
      "-rw-r--r--   2 akashpatel hdfs     216685 2020-04-17 15:36 /user/akashpatel/excercises/avro_dataset/output/orc/part-00000-60e7ab7f-1357-45cd-a63d-a2ebdab75dae-c000.snappy.orc\n",
      "-rw-r--r--   2 akashpatel hdfs      65020 2020-04-17 15:36 /user/akashpatel/excercises/avro_dataset/output/orc/part-00001-60e7ab7f-1357-45cd-a63d-a2ebdab75dae-c000.snappy.orc\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/excercises/avro_dataset/output/orc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orc = spark.read.format(\"orc\").load(\"/user/akashpatel/excercises/avro_dataset/output/orc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orc.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write.format(\"csv\").option(\"header\", \"true\").save(\"/user/akashpatel/excercises/avro_dataset/output/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 akashpatel hdfs          0 2020-04-17 16:19 /user/akashpatel/excercises/avro_dataset/output/csv/_SUCCESS\n",
      "-rw-r--r--   2 akashpatel hdfs     566350 2020-04-17 16:19 /user/akashpatel/excercises/avro_dataset/output/csv/part-00000-8c06fb89-87db-4110-8a0f-6f31c851f506-c000.csv\n",
      "-rw-r--r--   2 akashpatel hdfs     140459 2020-04-17 16:19 /user/akashpatel/excercises/avro_dataset/output/csv/part-00001-8c06fb89-87db-4110-8a0f-6f31c851f506-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/excercises/avro_dataset/output/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/user/akashpatel/excercises/avro_dataset/output/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|   registration_dttm| id|first_name|last_name|           email|gender|    ip_address|              cc|  country|birthdate|   salary|           title|comments|\n",
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "|2016-02-03T07:55:29Z|  1|    Amanda|   Jordan|ajordan0@com.com|Female|   1.197.201.2|6759521864920116|Indonesia| 3/8/1971| 49756.53|Internal Auditor|   1E+02|\n",
      "|2016-02-03T17:04:03Z|  2|    Albert|  Freeman| afreeman1@is.gd|  Male|218.111.175.34|            null|   Canada|1/16/1968|150280.17|   Accountant IV|    null|\n",
      "+--------------------+---+----------+---------+----------------+------+--------------+----------------+---------+---------+---------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avro.write.format(\"json\").save(\"/user/akashpatel/excercises/avro_dataset/output/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 akashpatel hdfs          0 2020-04-17 15:49 /user/akashpatel/excercises/avro_dataset/output/json/_SUCCESS\n",
      "-rw-r--r--   2 akashpatel hdfs    1183898 2020-04-17 15:49 /user/akashpatel/excercises/avro_dataset/output/json/part-00000-4701a1ca-2194-4fe7-a2b3-4549def25bf2-c000.json\n",
      "-rw-r--r--   2 akashpatel hdfs     294882 2020-04-17 15:49 /user/akashpatel/excercises/avro_dataset/output/json/part-00001-4701a1ca-2194-4fe7-a2b3-4549def25bf2-c000.json\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/akashpatel/excercises/avro_dataset/output/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = spark.read.format(\"json\").load(\"/user/akashpatel/excercises/avro_dataset/output/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/apps/hive/warehouse'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().get('spark.sql.warehouse.dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS akashpatel_avro_exercises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('USE akashpatel_avro_exercises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tbl = \"\"\"CREATE TABLE IF NOT EXISTS hive_table_from_AVRO\n",
    "                ()\"\"\"\n",
    "spark.sql(create_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"akashpatel_avro_exercises.hive_table_from_AVRO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - akashpatel hdfs          0 2020-04-17 16:05 /apps/hive/warehouse/akashpatel_avro_exercises.db/hive_table_from_avro\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /apps/hive/warehouse/akashpatel_avro_exercises.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from hive_table_from_AVRO\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
